{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtluohhLgW3a"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mongodb-developer/ai-agents-lab-notebooks/blob/main/notebook_template.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZa8mJ5IgW3b"
      },
      "source": [
        "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-agents-lab/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kMALXaMv-MS"
      },
      "source": [
        "# Step 1: Install libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxTXczeTghzU"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain langchainhub langchain-community langchain-fireworks \\\n",
        "langchain-huggingface langchain-mongodb arxiv pymupdf duckduckgo-search datasets pymongo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM8rg08YhqZe"
      },
      "source": [
        "# Step 2: Setup prerequisites\n",
        "\n",
        "Replace:\n",
        "\n",
        "- `<CODE_BLOCK_1>` with your **MongoDB connection string**\n",
        "- `<CODE_BLOCK_2>` with your **Fireworks API key**\n",
        "- `<CODE_BLOCK_3>` with your **LangSmith API key**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJnviw8dgW3c"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXLWCWEghuOX"
      },
      "outputs": [],
      "source": [
        "# Retain the quotes (\"\") when pasting the URI\n",
        "MONGODB_URI = \"<CODE_BLOCK_1>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_bGUQDWgW3d"
      },
      "outputs": [],
      "source": [
        "# Retain the quotes (\"\") when pasting the API key\n",
        "os.environ[\"FIREWORKS_API_KEY\"] = \"<CODE_BLOCK_2>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utcdsAHmgW3d"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "# Retain the quotes (\"\") when pasting the API key\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"<CODE_BLOCK_3>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUf3jtFzO4-V"
      },
      "source": [
        "# Step 3: Create a knowledge base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J5-qYazgW3d"
      },
      "source": [
        "### Download the dataset from Hugging Face\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8m5KrfmgW3d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from pymongo import MongoClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq4SA6r7O30i"
      },
      "outputs": [],
      "source": [
        "data = load_dataset(\"mongodb-eai/arxiv-embeddings\")\n",
        "dataset_df = pd.DataFrame(data[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo-qqGTLgW3e"
      },
      "outputs": [],
      "source": [
        "# Preview the dataset -- notice that the dataset already has an `embedding` column, which consists of embeddings of the paper abstracts.\n",
        "dataset_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf7n83FrgW3e"
      },
      "source": [
        "### Ingest data into MongoDB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRhLi5LwgW3e"
      },
      "source": [
        "ðŸ“š https://pymongo.readthedocs.io/en/stable/api/pymongo/mongo_client.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2gHwRjMfJlO"
      },
      "outputs": [],
      "source": [
        "# Initialize a MongoDB Python client\n",
        "client = <CODE_BLOCK_4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlGhskymgW3e"
      },
      "outputs": [],
      "source": [
        "# Name of the database -- Change if needed or leave as is\n",
        "DB_NAME = \"mongodb_agents_lab\"\n",
        "# Name of the collection -- Change if needed or leave as is\n",
        "COLLECTION_NAME = \"knowledge\"\n",
        "# Name of the vector search index -- Change if needed or leave as is\n",
        "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"vector_index\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k49tFOLjgW3e"
      },
      "source": [
        "ðŸ“š https://pymongo.readthedocs.io/en/stable/tutorial.html#getting-a-collection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esFLhON2gW3e"
      },
      "outputs": [],
      "source": [
        "# Connect to the collection defined above using the MongoDB client\n",
        "collection = <CODE_BLOCK_5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWLeaIM2gW3e"
      },
      "source": [
        "ðŸ“š https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJkyy9UbffZT"
      },
      "outputs": [],
      "source": [
        "# Bulk delete all existing records from the collection defined above -- should be a one-liner\n",
        "<CODE_BLOCK_6>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLxZT7R5gW3e"
      },
      "outputs": [],
      "source": [
        "# Ingest data into the collection\n",
        "records = dataset_df.to_dict(\"records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqyuL1AtgW3e"
      },
      "source": [
        "ðŸ“š https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01WAZS6HgW3e"
      },
      "outputs": [],
      "source": [
        "# Bulk insert `records` into the collection defined above -- should be a one-liner\n",
        "<CODE_BLOCK_7>\n",
        "\n",
        "print(\"Data ingestion into MongoDB completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brz0jVEVgW3e"
      },
      "source": [
        "# Step 4: Create a vector search index\n",
        "\n",
        "Follow the instructions in the documentation to create a Vector Search index in the Atlas UI.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1lmKhBgW3e"
      },
      "source": [
        "# Step 5: Instantiate chat completion LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YOF-h2dgW3e"
      },
      "outputs": [],
      "source": [
        "from langchain_fireworks import ChatFireworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddk9t4TVgW3e"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/integrations/chat/fireworks/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdEa82TUgW3f"
      },
      "outputs": [],
      "source": [
        "# Set the temperature for the chat model to 0.0 and max tokens to 1024\n",
        "llm = <CODE_BLOCK_8>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZfheX5FiIhU"
      },
      "source": [
        "# Step 6: Create agent tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woEzwvd_gW3f"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_community.document_loaders import ArxivLoader\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30Lmr29mgW3f"
      },
      "source": [
        "### Tool to fetch paper metadata from Arxiv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wus5juCwgW3f"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_paper_metadata_from_arxiv(topic: str) -> list:\n",
        "    \"\"\"\n",
        "    Fetch and return paper metadata for 5 Arxiv papers matching the given topic, for example: Retrieval Augmented Generation.\n",
        "\n",
        "    Args:\n",
        "    topic (str): The topic to find papers for on Arxiv.\n",
        "\n",
        "    Returns:\n",
        "    list: Metadata about the papers matching the topic.\n",
        "    \"\"\"\n",
        "    docs = ArxivLoader(query=topic, load_max_docs=5).load()\n",
        "    # Extract just the metadata from each document\n",
        "    metadata = [doc.metadata for doc in docs]\n",
        "    return metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYTOsPF2gW3f"
      },
      "source": [
        "### Tool to fetch the summary of a paper\n",
        "\n",
        "ðŸ“š https://python.langchain.com/v0.1/docs/integrations/document_loaders/arxiv/\n",
        "\n",
        "ðŸ“š https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.arxiv.ArxivLoader.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxM49fL7gW3f"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_paper_summary_from_arxiv(id: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetch and return the summary for a single research paper from Arxiv given the paper ID, for example: 1605.08386.\n",
        "\n",
        "    Args:\n",
        "    id (str): The paper ID.\n",
        "\n",
        "    Returns:\n",
        "    str: Summary of the paper.\n",
        "    \"\"\"\n",
        "    # Create a tool that uses the `ArxivLoader` document loader to return the paper summary given the paper ID (`id`).\n",
        "    # NOTE:\n",
        "        # Use the `get_summaries_as_docs` method of `ArxivLoader`\n",
        "        # Handle the case where the paper ID is invalid i.e., the number of docs returned from `ArxivLoader` are 0.\n",
        "    <CODE_BLOCK_9>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NJsEVZhgW3f"
      },
      "source": [
        "### Tool to answer questions based on information in the knowledge base\n",
        "\n",
        "In **Step 3**, we created a knowledge base for the agent. This tool should use the knowledge base to help the agent answer questions about topics. To do this, you will need to:\n",
        "\n",
        "- Create a MongoDB vector store\n",
        "\n",
        "- Get relevant documents from the vector store\n",
        "\n",
        "- Create a RAG chain that uses the retrieved documents and the LLM from **Step 5** to answer questions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7wmPlRXgW3f"
      },
      "source": [
        "#### Create a MongoDB Vector Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdv1woSxgW3f"
      },
      "outputs": [],
      "source": [
        "# Embedding model to use for the vector store -- DO NOT CHANGE\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2GDlgdXgW3f"
      },
      "source": [
        "ðŸ“š https://api.python.langchain.com/en/latest/_modules/langchain_mongodb/vectorstores.html#MongoDBAtlasVectorSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FW3rNuJgW3f"
      },
      "outputs": [],
      "source": [
        "# Create a MongoDBAtlas vector store\n",
        "# Use the `from_connection_string` method of the MongoDBAtlasVectorSearch class.\n",
        "# Arguments: connection_string, namespace, embedding, index_name, text_key\n",
        "# NOTE: Use variables defined in Steps 2, 3 and this step as values for the above arguments\n",
        "vector_store = <CODE_BLOCK_10>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_gaRD-CgW3f"
      },
      "source": [
        "#### Get relevant documents from the vector store\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYJWPG4ZgW3f"
      },
      "source": [
        "ðŸ“š https://github.com/langchain-ai/langchain/blob/master/libs/partners/mongodb/langchain_mongodb/vectorstores.py#L187\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVBzcZvJgW3f"
      },
      "outputs": [],
      "source": [
        "# Define a function to retrieve documents with a similarity score greater than 0.8 from the `vector_store`\n",
        "# Use the `similarity_search_with_score` method to get similar documents with their scores\n",
        "# Filter the retrieved list of documents to only return those with a score > 0.8\n",
        "def get_context(query):\n",
        "    <CODE_BLOCK_11>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C4Puzh5gW3f"
      },
      "source": [
        "#### Create a RAG chain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jAAGzvKgW3g"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/use_cases/question_answering/quickstart/\n",
        "\n",
        "ðŸ“š https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableLambda.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsyGx4zpgW3g"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def answer_questions_about_topics(query: str) -> list:\n",
        "    \"\"\"\n",
        "    Answer questions about a given topic based on information in the knowledge base.\n",
        "\n",
        "    Args:\n",
        "    query (str): User query about a topic.\n",
        "\n",
        "    Returns:\n",
        "    str: Information about the topic.\n",
        "    \"\"\"\n",
        "    # Create a RAG chain that uses the `llm` we instantiated in Step 4 and the `get_context` function above\n",
        "    # NOTE: Use `RunnableLambda` to convert the `get_context` function  into a Runnable\n",
        "    # Return the response of running `invoke` on the chain with `query` as an argument\n",
        "    <CODE_BLOCK_12>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv-ZiJNmgW3g"
      },
      "outputs": [],
      "source": [
        "# Create the list of tools\n",
        "tools = [\n",
        "    get_paper_metadata_from_arxiv,\n",
        "    get_paper_summary_from_arxiv,\n",
        "    answer_questions_about_topics,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gV5UPAegW3g"
      },
      "source": [
        "### Test out the tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn5sgbABgW3g"
      },
      "outputs": [],
      "source": [
        "# Test out the `get_paper_metadata_from_arxiv` tool\n",
        "get_paper_metadata_from_arxiv.invoke(\"Retrieval Augmented Generation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scQUSaO-gW3g"
      },
      "outputs": [],
      "source": [
        "# Test out the `get_paper_summary_from_arxiv` tool with paper ID 1808.09236\n",
        "<CODE_BLOCK_13>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcBjAUMNgW3g"
      },
      "outputs": [],
      "source": [
        "# Test out the `get_paper_summary_from_arxiv` with an invalid paper ID eg: 808.09236\n",
        "<CODE_BLOCK_14>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9yGZhKXgW3g"
      },
      "outputs": [],
      "source": [
        "# Test out the `answer_questions_about_topics` tool with the topic \"Partial cubes\"\n",
        "<CODE_BLOCK_15>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-BlTOCqgW3g"
      },
      "outputs": [],
      "source": [
        "# Test out the `answer_questions_about_topics` tool with a topic that is not present in the knowledge base eg:\"Tree of Thoughts\"\n",
        "<CODE_BLOCK_16>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eRCTswNgW3g"
      },
      "source": [
        "# ðŸ¦¹ Use web search to get information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwrUmeoogW3g"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain.docstore.document import Document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--zzHu0KgW3g"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.2/docs/integrations/tools/ddg/\n",
        "\n",
        "ðŸ“š https://stackoverflow.com/questions/76551067/how-to-create-a-langchain-doc-from-an-str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2zIFMEegW3g"
      },
      "outputs": [],
      "source": [
        "# Extend the `get_context` function from Step 6 to use DuckDuckGo search if no documents are retrieved from the knowledge base\n",
        "# NOTE: The result from DuckDuckGo search is a string and will need to be converted to a LangChain document for downstream use\n",
        "def get_context(query):\n",
        "    <CODE_BLOCK_17>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa60GM4KgW3g"
      },
      "outputs": [],
      "source": [
        "answer_questions_about_topics.invoke(\"Tree of Thoughts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Wb1-degW3g"
      },
      "source": [
        "# Step 7: Create a basic tool-calling agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCiRiftOgW3g"
      },
      "outputs": [],
      "source": [
        "from langchain.tools.render import render_text_description\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9vie-Q8gW3h"
      },
      "source": [
        "ðŸ“š https://api.python.langchain.com/en/latest/tools/langchain.tools.render.render_text_description.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVU4ZdB5gW3h"
      },
      "outputs": [],
      "source": [
        "# Try out a simple system prompt\n",
        "# Use the `render_text_description` method to include the list of tools the agent can access, in the prompt.\n",
        "system_message = <CODE_BLOCK_18>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN_SlNJDgW3h"
      },
      "source": [
        "### ðŸ¦¹ CoT prompting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNbPKUzJgW3h"
      },
      "outputs": [],
      "source": [
        "# system_message = f\"\"\"Given a question, write out in a step-by-step manner your reasoning\n",
        "# for how you will solve the problem to be sure that your conclusion is correct.\n",
        "# Avoid simply stating the correct answer at the outset. You can answer directly if the user\n",
        "# is greeting you or similar. Otherwise, you have access to the following tools:\n",
        "\n",
        "# {render_text_description(tools)}\n",
        "\n",
        "# Begin!\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owJ59PqcgW3h"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY13DrVXFDrm"
      },
      "outputs": [],
      "source": [
        "# Refer to the `Create Agent` and `Run Agent` sections in the docs above to craft a prompt, initialize an agent, and an agent executor\n",
        "# NOTE:\n",
        "    # Use the `system_message` above as the system prompt\n",
        "    # Do not include chat history in the prompt right now\n",
        "    # Name the agent executor object `agent_executor`\n",
        "<CODE_BLOCK_19>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyiOiLv4gW3h"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/modules/agents/how_to/handle_parsing_errors/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFy-ZQ7OgW3h"
      },
      "outputs": [],
      "source": [
        "# Test that the agent works as expected.\n",
        "# If it runs into parsing errors, add appropriate arguments to the `agent_executor` object and try again.\n",
        "agent_executor.invoke({\"input\": \"Give me papers on the topic prompt compression.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRzVkKfsgW3h"
      },
      "source": [
        "# Step 8: Create a ReAct agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqdr7PG6gW3h"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import create_react_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBABmwAMgW3h"
      },
      "outputs": [],
      "source": [
        "# Pull a ready-made react prompt from LangChain hub -- Modify if needed\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf2GBOH2gW3h"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/modules/agents/agent_types/react/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDReyD-ugW3h"
      },
      "outputs": [],
      "source": [
        "# Refer to the above docs to initialize a ReAct agent and the agent executor\n",
        "# NOTE:\n",
        "    # Use the `prompt` above as the agent prompt\n",
        "    # Do not include chat history in the prompt right now\n",
        "    # Name the agent executor object `agent_executor`\n",
        "<CODE_BLOCK_20>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWmra0UBgW3h"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/modules/agents/how_to/handle_parsing_errors/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR-qwK0NgW3h"
      },
      "outputs": [],
      "source": [
        "# Test that the agent works as expected.\n",
        "# If it runs into parsing errors, add appropriate arguments to the agent executor and try again.\n",
        "agent_executor.invoke({\"input\": \"Give me the summary for the paper 1808.09236.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYVv0I2AgW3i"
      },
      "source": [
        "# ðŸ¦¹ Create a custom agent without using abstractions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TppqffKhgW3i"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.output_parsers.tools import ToolsAgentOutputParser\n",
        "from langchain.agents.format_scratchpad.tools import (\n",
        "    format_to_tool_messages,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BObCl9YRgW3i"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/modules/agents/how_to/custom_agent/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A10K-pEGgW3i"
      },
      "outputs": [],
      "source": [
        "# Refer to the docs above to build a custom agent without using the `create_tool_calling_agent` abstraction.\n",
        "# NOTE:\n",
        "    # Do not include chat history in the prompt right now\n",
        "    # Name the agent executor object `agent_executor`\n",
        "<CODE_BLOCK_21>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OWSIgk-gW3i"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"Give me papers on the topic prompt compression.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4NU4ZjGl0WC"
      },
      "source": [
        "# Step 9: Add memory to agents using MongoDB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgO5XRbsgW3i"
      },
      "outputs": [],
      "source": [
        "from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V1di6NfgW3i"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.2/docs/integrations/memory/mongodb_chat_message_history/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A-3Fg1cjwyK"
      },
      "outputs": [],
      "source": [
        "# Define a function that returns an instance of `MongoDBChatMessageHistory`\n",
        "# Use variables defined in Steps 2 & 3 for the `connection_string` and `database_name` parameters\n",
        "# Choose a collection name of your choice to store the chat history\n",
        "def get_message_history(session_id: str) -> MongoDBChatMessageHistory:\n",
        "    <CODE_BLOCK_22>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nImkmr19gW3i"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/#create-agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI4uBAmNF5ll"
      },
      "outputs": [],
      "source": [
        "# Refer to the above docs and modify the code below to include chat history\n",
        "system_message = f\"\"\"Answer the following questions as best you can.\n",
        "You can answer directly if the user is greeting you or similar.\n",
        "Otherwise, you have access to the following tools:\n",
        "\n",
        "{render_text_description(tools)}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message),\n",
        "        <CODE_BLOCK_23>,\n",
        "        (\"human\", \"{input}\"),\n",
        "        # Placeholders fill up a **list** of messages\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWF_B5HzgW3i"
      },
      "source": [
        "ðŸ“š https://python.langchain.com/v0.1/docs/expression_language/how_to/message_history/#langsmith\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHgwfas-gW3i"
      },
      "outputs": [],
      "source": [
        "# Look at the example in the docs above to add and manage chat history for the agent.\n",
        "agent_with_chat_history = <CODE_BLOCK_24>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwMECBZBgW3i"
      },
      "outputs": [],
      "source": [
        "# Test the agent with chat history to make sure it works\n",
        "agent_with_chat_history.invoke(\n",
        "    {\"input\": \"Get me papers on Prompt Compression.\"},\n",
        "    config={\"configurable\": {\"session_id\": \"my-session\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r3Ohh8ZgW3i"
      },
      "outputs": [],
      "source": [
        "# Invoke the agent with a follow-up question to make sure that the chat history is being used\n",
        "<CODE_BLOCK_25>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RM8rg08YhqZe",
        "UUf3jtFzO4-V",
        "Sm5QZdshwJLN"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}